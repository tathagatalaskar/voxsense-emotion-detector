# ğŸ™ï¸ VoxSense â€” Indian Voice Emotion Detector

> I built this because I got tired of seeing "state-of-the-art" emotion AI fail completely on Indian voices.
> Every major dataset used to train these models was recorded by North American or European actors.
> Bengali, Hindi, Punjabi, Tamil â€” languages spoken by over a billion people â€” have zero representation.
> VoxSense is my attempt to start fixing that.

[![Live Demo](https://img.shields.io/badge/Live%20Demo-Try%20VoxSense-f97316?style=for-the-badge&logo=streamlit&logoColor=white)](https://voxsense-emotion-detector.streamlit.app)
[![GitHub](https://img.shields.io/badge/GitHub-tathagatalaskar-181717?style=for-the-badge&logo=github)](https://github.com/tathagatalaskar/voxsense-emotion-detector)


---

## The Problem

Here is something nobody talks about openly in the Speech AI world.

The five datasets that every emotion recognition model in the world is trained on:

| Dataset | Who recorded it | Language | Indian voices |
|---------|----------------|----------|---------------|
| RAVDESS | 24 North American professional actors | English | âŒ Zero |
| CREMA-D | 91 US actors | English | âŒ Zero |
| TESS | 2 Canadian actresses | English | âŒ Zero |
| SAVEE | 4 British males | English | âŒ Zero |
| EmoDB | German actors | German | âŒ Zero |

Researchers put it plainly in 2024:

> *"Very little work is carried out for SER for Indian corpus which has higher diversity,
> large number of dialects, and vast changes due to regional and geographical aspects â€”
> yet India is one of the largest customers of HMI systems and internet users."*
> â€” IIETA Journal of Artificial Intelligence Research, 2024

The real-world consequence of this gap is not theoretical.
Every call centre emotion tool deployed in India right now,
every mental health app that claims to detect user distress,
every edtech platform monitoring student engagement â€”
all of them are running models that have **never once heard an Indian voice.**

That felt wrong to me. So I started building.

---

## What VoxSense Does

Upload a voice recording in any Indian language â€” Hindi, Bengali, Punjabi, Tamil, Telugu,
Marathi, Malayalam, Hinglish, or Indian English â€” and VoxSense tells you
the emotional state of the speaker, displayed in English and four Indian scripts.

| Emotion | Bengali | Hindi | Punjabi | Malayalam |
|---------|---------|-------|---------|-----------|
| ğŸ˜Œ Calm | à¦¶à¦¾à¦¨à§à¦¤ | à¤¶à¤¾à¤‚à¤¤ | à¨¸à¨¼à¨¾à¨‚à¨¤ | à´¶à´¾à´¨àµà´¤à´‚ |
| ğŸ˜° Stressed | à¦šà¦¾à¦ªà§‡ | à¤¤à¤¨à¤¾à¤µ | à¨¤à¨£à¨¾à¨… | à´¸à´®àµà´®àµ¼à´¦àµà´¦à´‚ |
| ğŸ˜  Angry | à¦°à¦¾à¦— | à¤—à¥à¤¸à¥à¤¸à¤¾ | à¨—à©à©±à¨¸à¨¾ | à´•àµ‹à´ªà´‚ |
| ğŸ˜¨ Fearful | à¦­à¦¯à¦¼ | à¤¡à¤° | à¨¡à¨° | à´­à´¯à´‚ |
| ğŸ˜Š Happy | à¦†à¦¨à¦¨à§à¦¦ | à¤–à¥à¤¶à¥€ | à¨–à©à¨¸à¨¼à©€ | à´¸à´¨àµà´¤àµ‹à´·à´‚ |
| ğŸ˜” Sad | à¦¦à§à¦ƒà¦– | à¤¦à¥à¤– | à¨¦à©à©±à¨– | à´¸à´™àµà´•à´Ÿà´‚ |

It works on any Indian language because it analyses **voice patterns**, not words.
Pitch, energy, speech rate, spectral shape â€” these carry emotion regardless of
which language you are speaking.

---

## Why Language Calibration Matters

This is the part that makes VoxSense different from just running librosa on audio.

Bengali is vowel-rich with a naturally higher pitch baseline.
If you use the same pitch threshold for Bengali as you do for Hindi,
you will misclassify calm Bengali speech as stressed â€” every single time.

Punjabi is a tonal language with significantly higher energy output.
Tamil and Telugu belong to the Dravidian family with prosodic patterns
completely unlike Indo-Aryan languages.

VoxSense adjusts its thresholds per language family:
```
Bengali  â†’ +18Hz pitch offset Â· 0.88Ã— energy scale
Punjabi  â†’ +12Hz pitch offset Â· 1.18Ã— energy scale  
Tamil    â†’ +8Hz  pitch offset Â· 0.95Ã— energy scale (Dravidian)
Telugu   â†’ +6Hz  pitch offset Â· 0.97Ã— energy scale (Dravidian)
Marathi  â†’ +4Hz  pitch offset Â· 1.02Ã— energy scale
Hinglish â†’ +5Hz  pitch offset Â· language-agnostic processing
```

No existing open-source SER tool does this for Indian languages.

---

## How It Works
```
Your voice recording
        â†“
Feature Extraction  (librosa)
   â”œâ”€â”€ MFCC â€” 40-coefficient voice fingerprint
   â”œâ”€â”€ Pitch mean, std, range
   â”œâ”€â”€ RMS Energy mean, std, max
   â”œâ”€â”€ Zero Crossing Rate (speech rate proxy)
   â”œâ”€â”€ Spectral Centroid (brightness)
   â”œâ”€â”€ Spectral Contrast (clarity)
   â””â”€â”€ Tempo in BPM
        â†“
Language Calibration
   â””â”€â”€ Adjust thresholds for chosen language family
        â†“
Acoustic Classifier
   â””â”€â”€ Maps features â†’ 1 of 6 emotional states
        â†“
Result displayed in English + 4 Indian scripts
```

The classifier encodes the rules that a trained Random Forest or SVM
learns from labelled speech data â€” pitch ranges, energy bands,
spectral brightness zones, and tempo thresholds that correlate
with specific emotional states across Indian acoustic patterns.

---

## Tech Stack

| Layer | Tool |
|-------|------|
| Audio processing | `librosa` |
| Feature math | `numpy` |
| Web interface | `streamlit` |
| Charts | `plotly` |
| Classification | Acoustic rule system (RF-equivalent logic) |

---

## Run It Yourself
```bash
git clone https://github.com/tathagatalaskar/voxsense-emotion-detector
cd voxsense-emotion-detector
pip install -r requirements.txt
streamlit run app.py
```

Or just use the live version â€” it's free, permanent, no login needed:
ğŸ‘‰ **https://voxsense-emotion-detector.streamlit.app**

---

## Roadmap

This is a living project. Here is where it is going.

**Phase 1 â€” Acoustic MVP** âœ… Done
- Feature extraction pipeline (MFCC, pitch, energy, spectral, tempo)
- Language-calibrated classifier for 9 Indian languages
- 6-emotion detection with 4-script Indian labels
- Deployed live on Streamlit Cloud (permanent, free)

**Phase 2 â€” Real Training Data** ğŸ”„ In Progress
- Collect 1000+ labelled voice samples from native speakers
  across Bengali, Hindi, Punjabi, Tamil, and Telugu
- Train a proper supervised model (Random Forest â†’ CNN)
- Quantify the gap: benchmark against RAVDESS and CREMA-D
  to show exactly how much accuracy drops on Indian voices

**Phase 3 â€” Production**
- Open REST API so other developers can integrate emotion detection
- Real-time microphone detection (no upload needed)
- Mobile application in Flutter
- Pilot integration with rural mental health platforms
  and citizen grievance helpline systems

---

## Real-World Applications

**Healthcare** â€” Mental health monitoring in rural India where therapists are
scarce and telemedicine is the only option. Detect distress in patient voice
before a trained professional is even available.

**Citizen Services** â€” Flag emotionally distressed callers on grievance helplines
(112, CPGRAMS) automatically, so urgent cases get human attention faster.

**Education** â€” Detect student frustration during online exams and learning
sessions to offer timely support â€” especially important post-pandemic
where lakhs of students are learning entirely online.

---

## About

**Tathagata Laskar**
B.Tech, Computer Science Engineering
Chandigarh University
LinkedIn: https://www.linkedin.com/in/tathagata-laskar-b2048a276/

My mother tongue is Bengali â€” which is part of why this project exists.
I noticed that voice-based tools consistently performed worse
on my own voice compared to what the benchmarks claimed.
That observation turned into a research question,
which turned into this project.

ğŸŒ [voxsense-emotion-detector.streamlit.app](https://voxsense-emotion-detector.streamlit.app)
ğŸ™ [github.com/tathagatalaskar](https://github.com/tathagatalaskar)

---

*MIT License Â· Open Source Â· Built because 1.4 billion voices deserve to be heard accurately.*
